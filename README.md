# Research Paper Summerization using T5-
## Overview
This project implements an abstractive text summarization system for research articles using a fine-tuned T5-small transformer model. The model was trained on the arXiv subset of the scientific_papers dataset and evaluated with multiple NLP metrics (ROUGE, BLEU, METEOR, BERTScore). The goal is to assist researchers by generating concise, coherent summaries of lengthy scientific texts.

## Features
Preprocessing & tokenization of research papers

Fine-tuned T5-small model with Hugging Face

Evaluation with ROUGE, BLEU, METEOR, BERTScore

Beam search decoding for fluent summaries

Reproducible training pipeline
